{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190c69e4-1a17-46bf-a6ea-79760b4ef4ca",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions\n",
    "\n",
    " - [一、设置OpenAI API Key](#一、设置OpenAI-API-Key)\n",
    " - [二、Tagging](#二、Tagging)\n",
    "     - [2.1 创建Tagging函数](#2.1-创建Tagging函数)\n",
    "     - [2.2 通过LangChain实现Tagging](#2.2-通过LangChain实现Tagging)\n",
    "     - [2.3 结构化解析Tagging结果](#2.3-结构化解析Tagging结果)\n",
    " - [三、 Extraction](#三、Extraction)\n",
    "     - [3.1 创建Extraction函数](#3.1-创建Extraction函数)\n",
    "     - [3.2 通过LangChain实现创建Extraction函数](#3.2-通过LangChain实现创建Extraction函数)\n",
    "     - [3.3 结构化解析Extraction结果](#3.3-结构化解析Extraction结果)\n",
    " - [四、应用案例](#四、应用案例)\n",
    "     - [4.1 加载数据](#4.1-加载数据)\n",
    "     - [4.2 提取文章概览](#4.2-提取文章概览)\n",
    "     - [4.3 提取文章信息](#4.3-提取文章信息)\n",
    "     - [4.4 分块文本提取](#4.4-分块文本提取)\n",
    " - [五、英文版提示](#五、英文版提示)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff54f3b7-ff99-453c-a5cd-e6fb47569a50",
   "metadata": {},
   "source": [
    "# 一、设置OpenAI-API-Key\n",
    "\n",
    "登陆 [OpenAI 账户](https://platform.openai.com/account/api-keys) 获取API Key，然后将其设置为环境变量。\n",
    "\n",
    "- 如果你想要设置为全局环境变量，可以参考[知乎文章](https://zhuanlan.zhihu.com/p/627665725)。\n",
    "- 如果你想要设置为本地/项目环境变量，在本文件目录下创建`.env`文件, 打开文件输入以下内容。\n",
    "\n",
    "    <p style=\"font-family:verdana; font-size:12px;color:green\">\n",
    "    OPENAI_API_KEY=\"your_api_key\" \n",
    "    </p>\n",
    "  \n",
    "  替换\"your_api_key\"为你自己的 API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c248f2-a9c6-4b31-96a9-000f2b33322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载需要的包python-dotenv和openai\n",
    "# 如果你需要查看安装过程日志，可删除 -q\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b57c2ce-1610-4d9e-99eb-836d8b19e899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4210688-e41b-4b3c-baaf-7badb851b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.find_dotenv()寻找并定位.env文件的路径\n",
    "2.load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中\n",
    "3.如果你设置的是全局的环境变量，这行代码则没有任何作用\n",
    "\"\"\"\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf894094-198d-429d-96da-f7092cd7c44e",
   "metadata": {},
   "source": [
    "# 二、Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2fb4b-3678-48e2-bd81-edb485dfee05",
   "metadata": {},
   "source": [
    "Tagging是什么：\n",
    "- LLM给出一个函数描述，从输入文本中选择参数生成一个结构化的输出，形成函数调用\n",
    "- 更一般地说，LLM可以评估输入文本并生成**结构化输出**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4f577-1392-4905-a2ae-ea8afef211ec",
   "metadata": {},
   "source": [
    "## 2.1 创建Tagging函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da674fb-378a-4d8f-a66b-86b63db3f75b",
   "metadata": {},
   "source": [
    "我们定义了一个`Tagging`，它继承自Pydantic的BaseModel类，因此`Tagging`类也具备了严格的数据类型校验功能。`Tagging`类包含了2给成员变量：`sentiment`和`language`：\n",
    "- `sentiment`：用来判断用户信息的情感包括pos(正面)，neg(负面)，neutral(中立)。\n",
    "- `language`：用来判断用户使用的是哪国的语言，并且要符合ISO 639-1 编码规范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb3420e-2af6-4a1a-b88f-4accd1276b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from typing import List  \n",
    "from pydantic import BaseModel, Field  \n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc6e2bc-2b11-43ae-862f-6502efa87795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建 Tagging 类\n",
    "# 该类表是基于输入的文本来标记文本情感的 `pos`（正面）、`neg`（负面）或`neutral`（中立）\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"用特定信息标记这段文本。\"\"\"\n",
    "    # 文本的情绪标签，可选值为`pos`（正面）、`neg`（负面）或`neutral`（中立）\n",
    "    sentiment: str = Field(description=\"文本的情绪，请从“正面”、“负面”或“中立”中选择\")\n",
    "    # 文本的语言标签，应为ISO 639-1标准代码\n",
    "    language: str = Field(description=\"文本语言(应采用ISO 639-1代码)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfec0a8a-a6b5-4e21-873f-fd92ddfb379a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': '用特定信息标记这段文本。',\n",
       " 'parameters': {'title': 'Tagging',\n",
       "  'description': '用特定信息标记这段文本。',\n",
       "  'type': 'object',\n",
       "  'properties': {'sentiment': {'title': 'Sentiment',\n",
       "    'description': '文本的情绪，请从“正面”、“负面”或“中立”中选择',\n",
       "    'type': 'string'},\n",
       "   'language': {'title': 'Language',\n",
       "    'description': '文本语言(应采用ISO 639-1代码)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Tagging数据模型转换为OpenAI函数\n",
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7473b7-014b-4701-8105-38d45c51785f",
   "metadata": {},
   "source": [
    "## 2.2 通过LangChain实现Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cd10e-25c2-42e6-8e33-775df42d0240",
   "metadata": {},
   "source": [
    "接下来我们要将`Tagging`类转换成一个openai能识别的函数描述对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b30668a-18c0-41ff-ae7f-ecabc95d0300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.prompts import ChatPromptTemplate \n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d126bf6-404b-43dd-ac59-0e277af90d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个温度为0的ChatOpenAI模型实例\n",
    "model = ChatOpenAI(temperature=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72ef913-f7e8-4d85-b248-20619d616c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 应用 Tagging \n",
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a9ac-c9d9-41c5-a288-ac296d1f0cb1",
   "metadata": {},
   "source": [
    "有了函数描述变量，我们使用`LCEL`语法来创建一个chain。在这之前我们需要创建prompt，model，并绑定函数描述变量最后创建chain。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85658ed8-f059-4037-8bd8-97bf39d2bc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用ChatPromptTemplate的from_messages方法创建聊天提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"仔细思考，然后按指示标记文本\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a43649-440b-4f38-8756-5526addbf639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将模型与函数绑定，并指定函数调用的名称\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f5383d-cfcb-4ae1-9294-ca2090d843f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个标签链，结合提示模板和模型\n",
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d6db8f-3fd5-4adc-af4b-3f4e0e9d6ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Tagging', 'arguments': '{\\n  \"sentiment\": \"正面\",\\n  \"language\": \"zh\"\\n}'}}, example=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用标签链并传入输入文本\n",
    "tagging_chain.invoke({\"input\": \"我爱langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047e9611-58bf-41d5-9aec-a78429d33490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Tagging', 'arguments': '{\\n  \"sentiment\": \"中立\",\\n  \"language\": \"zh\"\\n}'}}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次调用标签链并传入另一个输入文本\n",
    "tagging_chain.invoke({\"input\": \"我想要问的不是这些问题\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef00b98-c368-46d2-8639-a0c69f360548",
   "metadata": {},
   "source": [
    "## 2.3 结构化解析Tagging结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e5f3e-269f-475c-9e0b-7d2da19c430f",
   "metadata": {},
   "source": [
    "以上输出LLM给出的AIMessage格式的结果，我们可以利用`LCEL`语法，在创建chain的时候附加一个json的输出解析器就可以解决这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98c9f30-4837-4ee1-8c91-54122a206323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从langchain.output_parsers.openai_functions模块导入JsonOutputFunctionsParser\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a92e037-32db-49f1-bbed-65a136449058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个新的标签链，结合提示模板、模型和JsonOutputFunctionsParser解析器\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48749566-8a75-4ce9-b2c9-1abad37f3763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': '正面', 'language': 'zh'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用标签链并传入输入文本\n",
    "tagging_chain.invoke({\"input\": \"我爱langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b7fbe-1e43-4167-8fbd-28a9df1b9ba7",
   "metadata": {},
   "source": [
    "# 三、Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e2fad-a8e4-48dd-8e29-eb6abd085b0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Extraction 是什么：\n",
    "- 提取（Extraction）类似于标记（Tagging），但用于提取多条信息。\n",
    "- 当给定一个输入Json模式时，LLM已经进行了微调，以查找并填充该模式的参数。\n",
    "- 该功能并不局限于function模式，可以用于一般用途的提取。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd5020-99b5-4b80-80bf-d58351968255",
   "metadata": {},
   "source": [
    "## 3.1 创建Extraction函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc4ae861-d0f8-4f78-b1cc-34c0ffd86daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from typing import Optional  \n",
    "from pydantic import BaseModel, Field  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e90392-7813-4a6e-9b0a-a8d1ee382368",
   "metadata": {},
   "source": [
    "定义了`Person`和`Information`两个类：\n",
    "- `person`类包含了2个成员，name和age，其中age是可选的。\n",
    "- `Information`类包含了一个people成员，它一个person的集合(List)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e5bcf4-952e-4095-b0fa-89cf94ce7dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建Person类\n",
    "class Person(BaseModel):\n",
    "    \"\"\"个人信息\"\"\"\n",
    "    name: str = Field(description=\"人的名字\")  # 人的名字\n",
    "    age: Optional[int] = Field(description=\"人的年龄\")  # 人的年龄，可选字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "502fe544-7138-4442-a8ce-86f40bff33be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建Information类别\n",
    "class Information(BaseModel):\n",
    "    \"\"\"要提取的信息\"\"\"\n",
    "    people: List[Person] = Field(description=\"关于人的信息列表\")  # 关于人的信息列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1647eea0-d025-484c-980b-03e44e80fff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': '要提取的信息',\n",
       " 'parameters': {'title': 'Information',\n",
       "  'description': '要提取的信息',\n",
       "  'type': 'object',\n",
       "  'properties': {'people': {'title': 'People',\n",
       "    'description': '关于人的信息列表',\n",
       "    'type': 'array',\n",
       "    'items': {'title': 'Person',\n",
       "     'description': '个人信息',\n",
       "     'type': 'object',\n",
       "     'properties': {'name': {'title': 'Name',\n",
       "       'description': '人的名字',\n",
       "       'type': 'string'},\n",
       "      'age': {'title': 'Age', 'description': '人的年龄', 'type': 'integer'}},\n",
       "     'required': ['name']}}},\n",
       "  'required': ['people']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Information数据模型转换为OpenAI函数\n",
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7dca14-4f0d-491d-b929-73a4087994e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建提取功能列表，并将提取功能绑定到模型上\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]  \n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8adc905c-0174-4d98-ac6b-ea4666f4c26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': '{\\n  \"people\": [\\n    {\\n      \"name\": \"乔\",\\n      \"age\": 30\\n    },\\n    {\\n      \"name\": \"玛莎\",\\n      \"age\": 0\\n    }\\n  ]\\n}'}}, example=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用提取模型，传入文本信息\n",
    "extraction_model.invoke(\"乔30岁，他妈妈叫玛莎\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f5fdb-0ad6-40c1-8ead-40b25a68f6ae",
   "metadata": {},
   "source": [
    "## 3.2 通过LangChain实现创建Extraction函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7566c1d1-d883-4bec-b302-9df251ba7dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用ChatPromptTemplate创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"提取相关信息，如果没有明确提供不要猜测。可以提取部分信息\"), \n",
    "    (\"human\", \"{input}\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cface60a-7df5-48cd-ba0e-899adc4c43bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建提取链，结合提示模板和提取模型\n",
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df3c3e1-00cd-4c98-92ed-4449748a47c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': '{\\n  \"people\": [\\n    {\\n      \"name\": \"乔\",\\n      \"age\": 30\\n    },\\n    {\\n      \"name\": \"玛莎\"\\n    }\\n  ]\\n}'}}, example=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用提取链并传入输入文本\n",
    "extraction_chain.invoke({\"input\": \"乔30岁，他妈妈叫玛莎\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4abd6e28-484f-4cc9-b819-b1e1c8ef1da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建新的提取链，加入JsonOutputFunctionsParser来解析输出\n",
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7349db35-8e43-4ce4-bfcb-80901033872a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': '乔', 'age': 30}, {'name': '玛莎'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次调用提取链\n",
    "extraction_chain.invoke({\"input\": \"乔30岁，他妈妈叫玛莎\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce50f8-a5c9-4016-b91b-e2014fd4707a",
   "metadata": {},
   "source": [
    "## 3.3 结构化解析Extraction结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "477ee923-96ac-4045-853f-ba92b867d14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec4bebd-b5a5-422b-97af-3b7a70e7bbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建提取链，指定关键字\"name\"来解析输出\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d83b810d-6ead-4e65-9cda-712076220884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '乔', 'age': 30}, {'name': '玛莎'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用提取链并传入输入文本\n",
    "extraction_chain.invoke({\"input\": \"乔30岁，他妈妈叫玛莎\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a4a40-8c85-4ae5-9a17-327f9aabcf79",
   "metadata": {},
   "source": [
    "# 四、应用案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b400b46-14c5-4447-9b27-58e1d21d1e7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "我们可以对更大的文本主体应用标记。例如，加载博客文章并从文本的子集中提取标记信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f45b1-e393-42e6-8d46-48c7531f74d5",
   "metadata": {},
   "source": [
    "## 4.1 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d19c7e1-beef-4fb1-82cf-1f44f080811f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用WebBaseLoader加载文档\n",
    "from langchain.document_loaders import WebBaseLoader  \n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\") \n",
    "documents = loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8619c412-9656-408e-b25d-0ac9fbee4918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取第一个文档\n",
    "doc = documents[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4431a99f-6504-4b49-baf2-6ede0d237e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取页面内容的前10000个字符\n",
    "page_content = doc.page_content[:10000]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a3eba-9a31-4b68-9bcd-c9e935ab72fb",
   "metadata": {},
   "source": [
    "## 4.2 提取文章概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b731cc-e14b-48b0-9d4f-c44cfeeb16f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从pydantic导入BaseModel和Field用于创建数据模型\n",
    "from pydantic import BaseModel, Field  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1a059-49e3-46d5-a2e0-4fcd3b8b34fd",
   "metadata": {},
   "source": [
    "定义一个Pydantic类`Overview`\n",
    "- `summary`：表示对文章内容的总结\n",
    "- `language`：表示文章所使用的语言\n",
    "- `keyword`：表示文章中的关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69db8f19-478c-48b0-a585-0e65342a6579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建Overview类别\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"一段文本的概述\"\"\"\n",
    "    summary: str = Field(description=\"提供内容的简明总结。\")  # 内容摘要\n",
    "    language: str = Field(description=\"提供编写内容所用的语言。\")  # 内容语言\n",
    "    keywords: str = Field(description=\"提供与内容相关的关键字。\")  # 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cb2410c-1745-4849-abc5-5bad827a939c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将Overview数据模型转换为OpenAI函数\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}  # 绑定函数调用\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()  # 创建标注链并加入解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f924cf88-1d96-4768-abe3-43883fdd8d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'LLM Powered Autonomous Agents is a concept of building agents with LLM (large language model) as its core controller. It involves several key components such as planning, memory, and tool use. The agent breaks down tasks into smaller subgoals, utilizes short-term and long-term memory, and learns to call external APIs for additional information. Self-reflection is also an important aspect for agents to improve iteratively. There are various techniques and frameworks, such as Chain of Thought, ReAct, Reflexion, and Chain of Hindsight, that enable agents to plan, reflect, and improve their performance.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, self-reflection, Chain of Thought, ReAct, Reflexion, Chain of Hindsight'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用标注链\n",
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c19007-dd0d-458e-a5db-e95ffa011b94",
   "metadata": {},
   "source": [
    "## 4.3 提取文章信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ccbb10f-13e0-43fb-a2bf-23b1ec0e925c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建Paper类，用于标题和作者\n",
    "class Paper(BaseModel):\n",
    "    \"\"\"提到的论文信息。\"\"\"\n",
    "    title: str  # 论文标题\n",
    "    author: Optional[str]  # 作者，可选字段\n",
    "\n",
    "# 创建Info，用户提取论文论文信息列表\n",
    "class Info(BaseModel):\n",
    "    \"\"\"要提取的信息\"\"\"\n",
    "    papers: List[Paper] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4950cb4c-c646-49fb-b967-3f6f55e65452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将Info数据模型转换为OpenAI函数\n",
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}  # 绑定函数调用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df7631d9-9d80-4be1-b5b7-18a3c6bf3466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建提取链并加入解析器\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abe10a14-5e36-4cda-8501-517b3960b19a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LLM Powered Autonomous Agents', 'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用提取链，发现提取了论文本身的名称。因此接下里可以结合prompt改进\n",
    "extraction_chain.invoke({\"input\": page_content})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b88ae3f-ab4c-48ed-975b-d1f8f8e96495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\n",
    "\"\"\"\n",
    "\n",
    "template_chinese = \"\"\"\n",
    "一篇文章将转交给你。把这篇文章中提到的所有论文都摘录出来。\n",
    "不要提取文章本身的名称。如果没有提到论文，那很好——你不需要提取任何论文!只返回一个空列表。\n",
    "不要编造或猜测任何额外的信息。只提取文本中的内容。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92d44ce2-c53d-4b7c-b127-546a22b82796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用定制化提示模板创建聊天提示\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template_chinese),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed458ec-d3aa-46e4-99f0-e23ad6635551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 重新创建提取链\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d79e06a-8e79-45c4-a58a-a07fb0cedb09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': ''},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'LLM+P (Liu et al. 2023)', 'author': ''},\n",
       " {'title': 'ReAct (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)', 'author': ''},\n",
       " {'title': 'Chain of Hindsight (CoH; Liu et al. 2023)', 'author': ''},\n",
       " {'title': 'Algorithm Distillation (AD; Laskin et al. 2023)', 'author': ''}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次调用提取链\n",
    "extraction_chain.invoke({\"input\": page_content})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30c3e3a9-b3d6-46f7-9611-888cec851cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用不相关输入调用提取链，不会返回有效信息\n",
    "extraction_chain.invoke({\"input\": \"hi\"})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c9a39e-5b3b-44c2-af3d-2f606bb2e033",
   "metadata": {},
   "source": [
    "## 4.4 分块文本提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43a295d3-fb11-4d02-bb0d-4c2ec7cbd0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "\n",
    "# 实例化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd20348f-0b3b-4fe6-ae2e-06cb2d0e9c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割文档内容，text_splitter可以将长文本切分成多个短文本\n",
    "splits = text_splitter.split_text(doc.page_content)  \n",
    "\n",
    "# 获取分割后的段落数量\n",
    "len(splits)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39c31923-8489-45a6-9d53-d3f721ef0524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义函数用于扁平化列表\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a56839b-df12-4e05-9c26-e21173a726e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例调用扁平化函数\n",
    "flatten([[1, 2], [3, 4]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81798ff6-33af-4064-87b0-742bf7d82113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n"
     ]
    }
   ],
   "source": [
    "# 打印第一个分割的文本块最后一千个字符\n",
    "print(splits[0][-1000:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54730f43-37e0-4cdf-ae1c-c42481c26906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.schema.runnable import RunnableLambda  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dd31032-787e-437c-b69d-bfef0bb1c40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建Lambda函数用于预处理文本\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17694d47-a3b2-4814-822a-d2fbebd5a230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': 'hi'}]\n",
      "1\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# 测试prep\n",
    "print(prep.invoke(\"hi\"))\n",
    "print(len(prep.invoke(\"hi\")))\n",
    "\n",
    "# 将长文本放入，会切分成多个短文本\n",
    "print(len(prep.invoke(doc.page_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8148b87-df91-4857-a4a2-30ed4ae52305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建链式调用，包括预处理、映射提取\n",
    "# 多个短文本分别使用extraction_chain进行提取，将结果的list通过flatten函数扁平化到一起\n",
    "chain = prep | extraction_chain.map() | flatten  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a67415cc-9567-4089-98a0-a298888087a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'AutoGPT', 'author': ''},\n",
       " {'title': 'GPT-Engineer', 'author': ''},\n",
       " {'title': 'BabyAGI', 'author': ''},\n",
       " {'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': ''},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'LLM+P (Liu et al. 2023)', 'author': ''},\n",
       " {'title': 'ReAct (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)', 'author': ''},\n",
       " {'title': 'Reflexion: A Framework for Self-Reflection in Reinforcement Learning',\n",
       "  'author': 'Shinn & Labash'},\n",
       " {'title': 'Chain of Hindsight: Improving Reinforcement Learning with Sequential Feedback',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'Algorithm Distillation: Learning Process of Reinforcement Learning',\n",
       "  'author': 'Laskin et al.'},\n",
       " {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n",
       " {'title': 'ED (expert distillation)', 'author': ''},\n",
       " {'title': 'RL^2', 'author': 'Duan et al. 2017'},\n",
       " {'title': 'Maximum Inner Product Search (MIPS)', 'author': ''},\n",
       " {'title': 'LSH (Locality-Sensitive Hashing)', 'author': ''},\n",
       " {'title': 'ANNOY (Approximate Nearest Neighbors Oh Yeah)', 'author': ''},\n",
       " {'title': 'HNSW (Hierarchical Navigable Small World)', 'author': ''},\n",
       " {'title': 'FAISS (Facebook AI Similarity Search)', 'author': ''},\n",
       " {'title': 'ScaNN (Scalable Nearest Neighbors)', 'author': ''},\n",
       " {'title': 'MRKL: Modular Reasoning, Knowledge and Language',\n",
       "  'author': 'Karpas et al. 2022'},\n",
       " {'title': 'TALM: Tool Augmented Language Models',\n",
       "  'author': 'Parisi et al. 2022'},\n",
       " {'title': 'Toolformer', 'author': 'Schick et al. 2023'},\n",
       " {'title': 'HuggingGPT', 'author': 'Shen et al. 2023'},\n",
       " {'title': 'API-Bank: A Benchmark for Evaluating Tool-Augmented Language Models',\n",
       "  'author': 'Li et al. 2023'},\n",
       " {'title': 'ChemCrow: A Domain-Specific Example of Tool-Augmented Language Models',\n",
       "  'author': 'Bran et al. 2023'},\n",
       " {'title': 'LLM-based evaluation of GPT-4 and ChemCrow', 'author': 'Unknown'},\n",
       " {'title': 'LLM-empowered agents for scientific discovery',\n",
       "  'author': 'Boiko et al. (2023)'},\n",
       " {'title': 'Generative Agents Simulation', 'author': 'Park, et al. (2023)'},\n",
       " {'title': 'Park et al. 2023', 'author': ''},\n",
       " {'title': 'Super Mario: A Classic Platform Game', 'author': 'John Smith'},\n",
       " {'title': 'MVC Architecture in Python', 'author': 'Jane Doe'},\n",
       " {'title': 'Keyboard Control in Python Games', 'author': 'David Johnson'},\n",
       " {'title': 'A Study on Machine Learning Algorithms', 'author': 'John Smith'},\n",
       " {'title': 'Deep Learning Techniques for Image Recognition',\n",
       "  'author': 'Jane Doe'},\n",
       " {'title': 'Natural Language Processing: A Comprehensive Review',\n",
       "  'author': 'David Johnson'},\n",
       " {'title': 'Chain of thought prompting elicits reasoning in large language models.',\n",
       "  'author': 'Wei et al.'},\n",
       " {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models.',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Chain of Hindsight Aligns Language Models with Feedback',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'ReAct: Synergizing reasoning and acting in language models.',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Reflexion: an autonomous agent with dynamic memory and self-reflection',\n",
       "  'author': 'Shinn & Labash'},\n",
       " {'title': 'In-context Reinforcement Learning with Algorithm Distillation',\n",
       "  'author': 'Laskin et al.'},\n",
       " {'title': 'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.',\n",
       "  'author': 'Karpas et al.'},\n",
       " {'title': 'API-Bank: A Benchmark for Tool-Augmented LLMs',\n",
       "  'author': 'Li et al.'},\n",
       " {'title': 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace',\n",
       "  'author': 'Shen et al.'},\n",
       " {'title': 'ChemCrow: Augmenting large-language models with chemistry tools.',\n",
       "  'author': 'Bran et al.'},\n",
       " {'title': 'Emergent autonomous scientific research capabilities of large language models.',\n",
       "  'author': 'Boiko et al.'},\n",
       " {'title': 'Generative Agents: Interactive Simulacra of Human Behavior.',\n",
       "  'author': 'Joon Sung Park, et al.'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a679c-6868-4371-9a1d-37c0b025b4ae",
   "metadata": {},
   "source": [
    "# 五、英文版模版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485f080-71a4-4c74-a95c-9c40f66c0504",
   "metadata": {
    "tags": []
   },
   "source": [
    "**2.1 创建Tagging函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01c31966-0818-419d-99a4-eac549b6f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c0ec4-0588-4e97-b499-1ebe833a18d8",
   "metadata": {},
   "source": [
    "**2.2 通过LangChain实现Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "773f4267-9891-404b-aae8-16861cb05040",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921e5e5-9f19-4da7-9e16-d76bc835ab13",
   "metadata": {},
   "source": [
    "**3.1 创建Extraction函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "594e546b-2fca-4e33-860a-fbb2bac87b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")  \n",
    "    age: Optional[int] = Field(description=\"person's age\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91a0bf4a-50b2-4c0b-8300-d32954403f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57409bf-5bc7-478d-8d5b-6cd6c8da4da5",
   "metadata": {},
   "source": [
    "**3.2 通过LangChain实现创建Extraction函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76e93f9b-c4dc-4eea-9ed7-12b3f0dfa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"), \n",
    "    (\"human\", \"{input}\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048db43-0a6e-49c0-a8ef-412dfbacfb85",
   "metadata": {},
   "source": [
    "**4.2 提取文章概览**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6591c7e4-9e5a-414b-8a79-6e262a7a315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\") \n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\") \n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd731da2-c4d2-484f-a2ec-5f4e64c6b79e",
   "metadata": {},
   "source": [
    "**4.3 提取文章信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d631b724-5e1e-465f-814a-874d006c4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str  \n",
    "    author: Optional[str]  \n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450aed7e-2f7b-47b1-916d-6e19cb3b5d60",
   "metadata": {},
   "source": [
    "prompt 使用 `template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87fc4e63-21f1-4082-9784-1c5355fb1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
