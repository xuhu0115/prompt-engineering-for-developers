{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3",
   "metadata": {},
   "source": [
    "# 对话代理 Conversational agent\n",
    "\n",
    " - [一、设置OpenAI API Key](#一、设置OpenAI-API-Key)\n",
    " - [二、逐步构建Agent](#二、逐步构建Agent)\n",
    "     - [2.1 定义Tools和Function](##2.1-定义Tools和Function)\n",
    "     - [2.2 加入中间步骤结果](##2.2-加入中间步骤结果)\n",
    "     - [2.3 加入对话历史](##2.3-加入对话历史)\n",
    " - [三、创建对话机器人](#三、创建对话机器人)\n",
    " - [四、总结](#四、总结)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5871cf03",
   "metadata": {},
   "source": [
    "# 一、设置OpenAI-API-Key\n",
    "\n",
    "登陆 [OpenAI 账户](https://platform.openai.com/account/api-keys) 获取API Key，然后将其设置为环境变量。\n",
    "\n",
    "- 如果你想要设置为全局环境变量，可以参考[知乎文章](https://zhuanlan.zhihu.com/p/627665725)。\n",
    "- 如果你想要设置为本地/项目环境变量，在本文件目录下创建`.env`文件, 打开文件输入以下内容。\n",
    "\n",
    "    <p style=\"font-family:verdana; font-size:12px;color:green\">\n",
    "    OPENAI_API_KEY=\"your_api_key\" \n",
    "    </p>\n",
    "  \n",
    "  替换\"your_api_key\"为你自己的 API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载需要的包python-dotenv和openai\n",
    "# 如果你需要查看安装过程日志，可删除 -q\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36261434-a96c-49e8-ad41-918d14da089a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "985f0c67",
   "metadata": {},
   "source": [
    "# 二、逐步构建Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9131b422",
   "metadata": {},
   "source": [
    "## 2.1-定义Tools和Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f44fbb-6708-4fce-bac4-55dc261e3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入tool包\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7406eb-334b-43d0-8110-31656a55b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# 定义输入格式\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\") #要获取天气数据的位置的纬度\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\") #要获取天气数据的位置的经度\n",
    "\n",
    "# 使用 @tool 装饰器并指定输入格式\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    # Open Meteo API 的URL\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # 请求参数\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # 发送 API 请求\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    # 检查响应状态码\n",
    "    if response.status_code == 200:\n",
    "        # 解析 JSON 响应\n",
    "        results = response.json()\n",
    "    else:\n",
    "        # 处理请求失败的情况\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    # 获取当前 UTC 时间\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    \n",
    "    # 将时间字符串转换为 datetime 对象\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    \n",
    "    # 获取温度列表\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    # 找到最接近当前时间的索引\n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    \n",
    "    # 获取当前温度\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    # 返回当前温度的字符串形式\n",
    "    return f'The current temperature is {current_temperature}°C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac0a1e7-567f-4775-a538-351a5ff099e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# 定义维基百科搜索的tool\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]: #取前三个页面标题\n",
    "        try:\n",
    "            #使用 wikipedia 模块的 page 函数，获取指定标题的维基百科页面对象。\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False) \n",
    "            # 获取页面摘要\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入tools列表\n",
    "tools = [get_current_temperature, search_wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf0d789-559b-42df-9d6d-77a0cd8888d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ce7cb-099c-4f43-a548-b355a5b66511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将工具格式化为 OpenAI 函数\n",
    "functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "\n",
    "# 创建 ChatOpenAI 模型，设置温度为 0，绑定生成的 OpenAI 函数列表\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "\n",
    "# 创建 ChatPromptTemplate，从消息模板中获取用户输入\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 创建处理链，将 prompt、model 和 OpenAIFunctionsAgentOutputParser 连接起来\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"what is the weather is sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1dbc697-3e0a-4197-8ddc-2894763b4b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看调用的工具\n",
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab829b59-803f-488f-bcf3-5119c224baa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看工具的输入\n",
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7505c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zh = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个有帮助的而且安全可靠的助手\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain_zh = prompt_zh | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ca8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"现在圣弗朗西斯科的温度是多少度？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7b379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd378dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a8e21dd",
   "metadata": {},
   "source": [
    "## 2.2-加入中间步骤结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b4d483-c498-4932-a373-bc2f4da17c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 ChatPromptTemplate，从消息模板中获取用户输入\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\") # 解析和验证关键字参数中的输入数据\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ac6ea2-0e20-424a-ba33-6f8d627379b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建处理链，将 prompt、model 和 OpenAIFunctionsAgentOutputParser 连接起来\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bada1de8-d7c4-4880-98c2-d47cc65f684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用\n",
    "result1 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\",\n",
    "    \"agent_scratchpad\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5f4e61-36a3-4d80-9c49-0b83cedb1592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看调用的工具\n",
    "result1.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11845c11-7d41-455a-8ac0-4b8161acaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取tool调用的结果\n",
    "observation = get_current_temperature(result1.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "810184c8-8495-4189-b83e-17220cf65bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 9.1°C'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看结果\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c1b223d-ea2a-414c-924c-512c4c9da66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看输出类型\n",
    "type(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61853679-75b5-4462-8059-f1214286a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72ca4278-165a-4915-8ec6-09e696f29d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看调用日志\n",
    "result1.message_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e079a7-d58c-41c0-8762-4e183e72a1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}),\n",
       " FunctionMessage(content='The current temperature is 9.1°C', name='get_current_temperature')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Function和Tool的结果转换成openai函数格式\n",
    "format_to_openai_functions([(result1, observation), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09735a9e-452d-472b-a4c0-35c315e9e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造成Agent的输入格式，agent_scratchpad是中间步骤的结果\n",
    "result2 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\", \n",
    "    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9df61ecc-52fe-4fae-85a2-dbb61d68e2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 9.1°C.'}, log='The current temperature in San Francisco is 9.1°C.')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看Agent的输出结果\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9dd139f-e06a-4148-a025-ae100851c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "def run_agent(user_input):\n",
    "    # 存储中间步骤的列表\n",
    "    intermediate_steps = []\n",
    "\n",
    "    # 循环执行 agent 操作\n",
    "    while True:\n",
    "        # 调用处理链的 invoke 方法，传递用户输入和中间步骤的 OpenAI 函数形式\n",
    "        result = chain.invoke({\n",
    "            \"input\": user_input,\n",
    "            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
    "        })\n",
    "\n",
    "        # 如果结果是 AgentFinish 类型，则结束运行并返回结果\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "\n",
    "        # 根据结果中的工具名称选择相应的工具函数\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia,\n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "\n",
    "        # 运行选定的工具函数，并获取观察结果\n",
    "        observation = tool.run(result.tool_input)\n",
    "\n",
    "        # 将结果和观察结果添加到中间步骤列表\n",
    "        intermediate_steps.append((result, observation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f6c1121-70a6-41ae-8c3d-41f7cfc756af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 创建 RunnablePassthrough，用于将 agent_scratchpad存储的中间步骤结果转换为 OpenAI 函数形式\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad=lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a05df88-4ad9-4c48-a7dd-6b42db91cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个运行 agent 的函数\n",
    "def run_agent(user_input):\n",
    "    # 存储中间步骤的列表\n",
    "    intermediate_steps = []\n",
    "\n",
    "    # 循环执行 agent 操作\n",
    "    while True:\n",
    "        # 通过 agent_chain 调用 invoke 方法，传递用户输入和中间步骤的列表\n",
    "        result = agent_chain.invoke({\n",
    "            \"input\": user_input,\n",
    "            \"intermediate_steps\": intermediate_steps\n",
    "        })\n",
    "\n",
    "        # 如果结果是 AgentFinish 类型，则结束循环并返回结果\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "\n",
    "        # 根据结果中的工具名称选择相应的工具函数\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia,\n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "\n",
    "        # 运行选定的工具函数，并获取观察结果\n",
    "        observation = tool.run(result.tool_input)\n",
    "\n",
    "        # 将结果和观察结果添加到中间步骤列表\n",
    "        intermediate_steps.append((result, observation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8bf88b6-9992-4041-8344-ef4921bf3cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 9.1°C.'}, log='The current temperature in San Francisco is 9.1°C.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试获取温度的tool\n",
    "run_agent(\"what is the weather is sf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23417203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': '圣弗朗西斯科目前的温度是9.1°C。'}, log='圣弗朗西斯科目前的温度是9.1°C。')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"圣弗朗西斯科的温度是多少？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c94a493-b480-409a-968a-038c8895709c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.'}, log='LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases including document analysis and summarization, chatbots, and code analysis.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试维基百科搜索摘要的tool\n",
    "run_agent(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d96a0838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'LangChain是一个旨在简化使用大型语言模型（LLMs）创建应用程序的框架。作为一个语言模型集成框架，LangChain的用例主要涵盖了文档分析和摘要、聊天机器人以及代码分析等领域。'}, log='LangChain是一个旨在简化使用大型语言模型（LLMs）创建应用程序的框架。作为一个语言模型集成框架，LangChain的用例主要涵盖了文档分析和摘要、聊天机器人以及代码分析等领域。')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"什么是langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c8c6fd7-7c8c-487a-81de-1dcff739a2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Well, hello there! How can I assist you today?'}, log='Well, hello there! How can I assist you today?')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试非tool调用\n",
    "run_agent(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "267d33eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': '你好！有什么可以帮助你的吗？'}, log='你好！有什么可以帮助你的吗？')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"你好！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b270a064-8cf1-44da-a59e-be622f9099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用AgentExecutor对agent进行封装\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87baebf4-2555-4e98-aece-a1c327644817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: OpenAI\n",
      "Summary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\n",
      "As one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial board members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft's Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases that overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework with use-cases that overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "agent_executor.invoke({\"input\": \"what is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e52292b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: OpenAI\n",
      "Summary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\n",
      "As one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial board members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft's Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\u001b[0m\u001b[32;1m\u001b[1;3mLangChain 是一个旨在简化使用大型语言模型（LLMs）创建应用程序的框架。作为一个语言模型集成框架，LangChain 的用例主要涵盖了文档分析和摘要、聊天机器人以及代码分析等领域。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '什么是langchain?',\n",
       " 'output': 'LangChain 是一个旨在简化使用大型语言模型（LLMs）创建应用程序的框架。作为一个语言模型集成框架，LangChain 的用例主要涵盖了文档分析和摘要、聊天机器人以及代码分析等领域。'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"什么是langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2da813c-47c3-487e-8c43-444c9b4d9821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ca7b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好，Bob！有什么可以帮助你的吗？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我的名字是bob', 'output': '你好，Bob！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"我的名字是bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15ba8a9f-fcb2-44d0-878f-3017f607e955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm sorry, I don't have access to your personal information. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name',\n",
       " 'output': \"I'm sorry, I don't have access to your personal information. How can I assist you today?\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "agent_executor.invoke({\"input\": \"what is my name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee259c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你的名字是用户。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我的名字是什么？', 'output': '你的名字是用户。'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"我的名字是什么？\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d180426",
   "metadata": {},
   "source": [
    "## 3.3-加入对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d1df28a-27da-4f8e-ab03-a37a276db74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入用户的对话历史\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8598e87-de8a-4710-a90e-2a919adc00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造agent的处理链\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3865c2c-cb80-4341-bcbe-3b5150749622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入对话记忆模块\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40b036fc-446f-4075-9a92-9a4bac6ecb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37f70acf-57ff-4ab9-a942-f0ad6e680c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?')],\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试tool\n",
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bad2f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我的名字是bob',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='我的名字是bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?')],\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"我的名字是bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1554b0c-8c72-4d8d-bbed-20afd94828c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. How can I assist you today, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats my name',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='我的名字是bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob. How can I assist you today, Bob?')],\n",
       " 'output': 'Your name is Bob. How can I assist you today, Bob?'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试tool\n",
    "agent_executor.invoke({\"input\": \"whats my name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7c51371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你的名字是 Bob。有什么我可以帮助你的吗？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我的名字是什么？',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='我的名字是bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob. How can I assist you today, Bob?'),\n",
       "  HumanMessage(content='我的名字是什么？'),\n",
       "  AIMessage(content='你的名字是 Bob。有什么我可以帮助你的吗？')],\n",
       " 'output': '你的名字是 Bob。有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"我的名字是什么？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40887f61-6746-4e51-852d-5ff0457384b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe current temperature is 9.1°C\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='我的名字是bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob. How can I assist you today, Bob?'),\n",
       "  HumanMessage(content='我的名字是什么？'),\n",
       "  AIMessage(content='你的名字是 Bob。有什么我可以帮助你的吗？'),\n",
       "  HumanMessage(content='whats the weather in sf?'),\n",
       "  AIMessage(content='The current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?')],\n",
       " 'output': 'The current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试tool\n",
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efadf455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe current temperature is 9.1°C\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '圣弗朗西斯科现在的温度是多少？',\n",
       " 'chat_history': [HumanMessage(content='my name is bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='我的名字是bob'),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content='Your name is Bob. How can I assist you today, Bob?'),\n",
       "  HumanMessage(content='我的名字是什么？'),\n",
       "  AIMessage(content='你的名字是 Bob。有什么我可以帮助你的吗？'),\n",
       "  HumanMessage(content='whats the weather in sf?'),\n",
       "  AIMessage(content='The current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?'),\n",
       "  HumanMessage(content='圣弗朗西斯科现在的温度是多少？'),\n",
       "  AIMessage(content='The current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?')],\n",
       " 'output': 'The current temperature in San Francisco is 9.1°C. Is there anything else you would like to know?'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"圣弗朗西斯科现在的温度是多少？\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34b0b511-21d6-4c7e-b4e2-f886bc296997",
   "metadata": {},
   "source": [
    "# 三、 创建对话机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1cd4bd2-703e-4e4e-8f5c-ae3d491a41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义的工具（自由发挥）\n",
    "@tool\n",
    "def create_your_own(query: str) -> str:\n",
    "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
    "    print(type(query))\n",
    "    return query[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67cb6fdc-ff55-4a7b-8a39-1871006aa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将之前定义的工具加入工具列表\n",
    "tools = [get_current_temperature, search_wikipedia, create_your_own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66a73e69-acfb-471e-b54d-8ac586235521",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'panel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpanel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpn\u001b[39;00m  \u001b[38;5;66;03m# GUI\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pn\u001b[38;5;241m.\u001b[39mextension()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpanel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'panel'"
     ]
    }
   ],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "import panel as pn\n",
    "import param\n",
    "\n",
    "# 定义 cbfs 类\n",
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    # 初始化函数\n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []  # 存储 GUI 面板\n",
    "        self.functions = [format_tool_to_openai_function(f) for f in tools]  # 将tools格式化为 OpenAI 函数\n",
    "        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)  # 创建 ChatOpenAI 模型\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")  # 创建 ConversationBufferMemory\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are helpful but sassy assistant\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])  # 创建 ChatPromptTemplate\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()  # 创建处理链\n",
    "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)  # 创建 AgentExecutor\n",
    "    \n",
    "    # 对话链函数\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output']\n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    # 清除历史记录函数\n",
    "    def clr_history(self, count=0):\n",
    "        self.chat_history = []\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c3827-87fc-4dbe-a566-ca95b3f9068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 cbfs 对象，传递工具列表\n",
    "cb = cbfs(tools)\n",
    "\n",
    "# 创建文本输入框组件\n",
    "inp = pn.widgets.TextInput(placeholder='Enter text here…')\n",
    "\n",
    "# 将 convchain 方法与输入框进行绑定，形成对话链\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "# 创建第一个选项卡组件\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),  # 显示文本输入框\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation, loading_indicator=True, height=400),  # 显示对话链面板\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "# 创建仪表板，包含标题和选项卡\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# QnA_Bot')),  # 显示标题\n",
    "    pn.Tabs(('Conversation', tab1))  # 创建选项卡\n",
    ")\n",
    "\n",
    "# 显示仪表板\n",
    "dashboard\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41804e2f-4dc1-4763-8893-5e76ab5d8f14",
   "metadata": {},
   "source": [
    "# 四、总结\n",
    "\n",
    "总结一下构建对话机器人的流程：\n",
    "\n",
    "定义tools和functions --> 构建模型 --> 加入中间步骤结果 --> 加入记忆机制 --> 交互界面  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013d846-a23a-40b8-95e4-fc46306b4258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e229098-b7fe-4a3c-b1d0-4390f8cdf648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
